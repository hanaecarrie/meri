# coding: utf-8
""" Module that declare the reporting class that handle the ouput of a study and
provide helper to access it.
"""
# system import
import numpy as np


class ReportGridSearch(object):
    """A reporting class generated by the function grid_search containing all
    the reconstructed image, the given parameters, the error measurement,
    and differents methods to select the best parameters w.r.t a specific
    metrics.
    """
    def __init__(self, list_kwargs, param_grid, recons_im, im_ref,
                 metrics_funcs, metrics_direction, errs):
        """ Init the class.

        Parameters:
        ----------
        list_kwargs: list of dictionary,
            the list of all the 'tested' parameter for the reconstruction.
        list_params: list of dictionary,
            the list of all the 'tested' parameter for the reconstruction.
        param_grid: dict or list of dictionaries,
            Dictionary with parameters names (string) as keys and lists of
            parameter settings to try as values.
        recons_im: list of np.ndarray
            the list of the reconstructed image. It should respect the same
            order than list_kwargs.
        im_ref: np.ndarray;
            reference image which were used to compute the errs.
        metrics_funcs: list of functions,
            The list of functions for the error measurement. Each one should
            only accept two arguments: im and ref and each function should
            return a real number.
        metrics_direction: list of bool,
            specify if the metrics mean: True if the lower the better, False for
            the greater the better. It will be directly pass to the report
            result.
        errs: list of dictionary
            the list of all the metrics errors for each reconstructed image. It
            should respect the same order than list_kwargs (and so recons_im).
        """
        self.list_kwargs = list_kwargs
        self.param_grid = param_grid
        self.recons_im = recons_im
        self.im_ref = im_ref
        self.metrics_funcs = metrics_funcs
        self.metrics_direction = metrics_direction
        self.errs = errs
        self.fixed_params = self._get_fixed_params()
        self.floatting_params = self._get_floatting_params()

    ####
    ## getter methods

    def get_list_params(self, param_name):
        """ Getter for the list of value submitted for the given parameter.

        Parameters:
        -----------
        param_name: str,
            the parameter name of desired parameter.

        Return:
        -------
        params: list
            list of the values for the given parameter.
        """
        return self.param_grid[param_name]

    def _get_fixed_params(self):
        """ Private helper that return the list of parameters name that have a
        single value.

        Return:
        -------
        fixed_params: list of str
            list of parameters name that have a single value.
        """
        return [key for key, value in self.param_grid.iteritems()
                if len(value) == 1]

    def _get_floatting_params(self):
        """ Private helper that return the list of parameters name that have a
        single value.

        Return:
        -------
        fixed_params: list of str
            list of parameters name that have a single value.
        """
        return [key for key, value in self.param_grid.iteritems()
                if len(value) > 1]

    def _get_studies_filter(self, filter_):
        """ Private helper that return index list based on filter in kwargs.

        Parameters:
        -----------
        filter_:

        Return:
        -------
        filter_: list of int,
            mask to consider only the studies which the index is in filter_ .
        """
        if filter_ is None:
            idx_filter = range(len(self.recons_im))
        elif isinstance(filter_, list):
            idx_filter = filter_
        elif isinstance(filter_, dict):
            # sanitize filter_ dict
            for key, value in filter_.iteritems():
                if not isinstance(value, list):
                    filter_[key] = [value]
            idx_filter = []
            for idx, kwargs in enumerate(self.list_kwargs):
                drop = False # if True will ignore this study
                # loop to check if the study match the new restricted
                #Â parameters grid
                for key, value in kwargs.iteritems():
                    if (key in self.fixed_params) or (key not in filter_):
                        continue
                    if value not in filter_[key]:
                        drop = True
                if not drop:
                    idx_filter.append(idx)
        else:
            raise ValueError("filter_ type not understood, "
                             "got {0}".format(type(filter_)))
        return idx_filter

    def _all_score(self, metric, filter_):
        """ Private helper that return all the score for the given metric.

        Parameters:
        -----------
        metric: string or function,
            the exact metric function name, example: 'compare_mse'
            from metric or the metric function itself.

        filter_: list of int,
            mask to consider only the studies which the index is in filter_ .

        Return:
        ------
        all_score: np.ndarray,
            all the measure error for the given metric, respect the order same
            order than list_kwargs, recons_im and errs attributes.
        """
        if filter_ is None:
            filter_ = range(len(self.recons_im))
        if callable(metric):
            metric = metric.func_name
        return np.array([errs[metric] for idx, errs in enumerate(self.errs) if idx in filter_])

    ####
    ## best getter methods

    def best_image(self, metric, filter_=None):
        """ Return the best reconstructed image for the given metric.

        Parameters:
        -----------
        metric: string or function
            the exact metric function name, example: 'compare_mse'
            from metric or the metric function itself.

        filter_:

        Return:
        -------
        best_image: np.ndarray,
            the best reconstructed image for the given metric.
        """
        filter_ = self._get_studies_filter(filter_)
        best_idx = self.best_index(metric, filter_)
        return self.recons_im[best_idx]

    def best_score(self, metric, filter_=None):
        """ Return the best score for the given metric.

        Parameters:
        -----------
        metric: string or function
            the exact metric function name, example: 'compare_mse'
            from metric or the metric function itself.

        filter_:

        Return:
        -------
        best_score: float,
            the best score for the given metric.
        """
        filter_ = self._get_studies_filter(filter_)
        best_idx = self.best_index(metric, filter_)
        return self._all_score(metric, filter_)[best_idx]

    def best_params(self, metric, filter_=None):
        """ Return the best set of parameters for the given metric.

        Parameters:
        -----------
        metric: string or function
            the exact metric function name, example: 'compare_mse'
            from metric or the metric function itself.

        filter_:

        Return:
        -------
        best_params: dictionary,
            the best params for the given metric.
        """
        filter_ = self._get_studies_filter(filter_)
        best_idx = self.best_index(metric, filter_)
        return self.list_kwargs[best_idx]

    def best_index(self, metric, filter_=None):
        """ Return the index of the best set of parameters for the given metric.

        Parameters:
        -----------
        metric: string or function
            the exact metric function name, example: 'compare_mse'
            from metric or the metric function itself.

        filter_:

        Return:
        -------
        best_index: int,
            the index of the best set of parameters.
        """
        if callable(metric):
            metric = metric.func_name
        filter_ = self._get_studies_filter(filter_)
        if self.metrics_direction[metric]:
            return np.argmin(self._all_score(metric, filter_))
        else:
            return np.argmax(self._all_score(metric, filter_))

    ####
    ## diff methods

    def diffref_best_image(self, metric):
        """ Return the difference between the reference image and the
        best image for the given metric

        Parameters:
        -----------
        metric: string or function
            the exact metric function name, example: 'compare_mse'
            from metric or the metric function itself.

        Return:
        -------
        diff: np.ndarray,
            the difference, recons_im[idx] - im_ref, between the reference
            image and the best image for the given metric.
        """
        return self.best_image(metric) - self.im_ref

    def diffref_image(self, idx):
        """ Return the difference between the reference image and the
        image with ithe given idx w.r.t to the order of list_kwargs.

        Parameters:
        -----------
        idx: int,
            the idx of recons image to inspect w.r.t to the order of list_kwargs.

        Return:
        -------
        diff: np.ndarray,
            the difference, recons_im[idx] - im_ref, between the reference
            image and the image with the given idx w.r.t to the order of
            list_kwargs.
        """
        return self.recons_im[idx] - self.im_ref


    def diff_image(self, idx, idxref):
        """ Return the difference between the images with the given idx w.r.t
        to the order of list_kwargs.

        Parameters:
        -----------
        idx: int,
            the idx of recons image to inspect w.r.t to the order of list_kwargs.
        idxref: int,
            the idx of recons image considered as ref  w.r.t to the order of
            list_kwargs.

        Return:
        -------
        diff: np.ndarray,
            the difference, recons_im[idx] - im_ref, between the reference
            image and the image with the given idx w.r.t to the order of
            list_kwargs.
        """
        return self.recons_im[idx] - self.recons_im[idxref]
